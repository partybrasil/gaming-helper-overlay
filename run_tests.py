#!/usr/bin/env python3
"""
ğŸ§ª Gaming Helper Overlay - Test Runner
Ejecutor de tests con opciones avanzadas y diagnÃ³stico
"""

import sys
import argparse
import subprocess
from pathlib import Path

def print_header():
    """Mostrar header del test runner"""
    print(f"\n{'='*60}")
    print("ğŸ§ª Gaming Helper Overlay - Test Runner")
    print(f"{'='*60}")

def print_available_tests():
    """Mostrar tests disponibles"""
    tests = {
        'all': 'Ejecutar todos los tests (49 tests)',
        'environment': 'Tests de entorno de desarrollo',
        'dependencies': 'Tests de dependencias y librerÃ­as',
        'core': 'Tests de mÃ³dulos principales',
        'config': 'Tests de configuraciÃ³n YAML',
        'plugins': 'Tests del sistema de plugins',
        'app': 'Tests de aplicaciÃ³n principal',
        'ui': 'Tests de componentes UI',
        'threads': 'Tests de gestiÃ³n de hilos',
        'tools': 'Tests de herramientas',
        'specific': 'Tests de plugins especÃ­ficos',
        'assets': 'Tests de gestiÃ³n de assets',
        'files': 'Tests de estructura de archivos',
        'integration': 'Tests de integraciÃ³n',
        'performance': 'Tests de rendimiento',
        'quick': 'Diagnosis rÃ¡pida bÃ¡sica',
        'critical': 'Solo tests crÃ­ticos (environment + dependencies + core)'
    }
    
    print("\nğŸ“‹ Tests Disponibles:")
    print("-" * 40)
    for test, desc in tests.items():
        print(f"  {test:<12} : {desc}")

def run_quick_diagnosis():
    """Ejecutar diagnosis rÃ¡pida"""
    print("\nğŸ” Ejecutando diagnosis rÃ¡pida...")
    
    # Verificar Python
    version = sys.version_info
    if version >= (3, 10):
        print(f"âœ… Python {version.major}.{version.minor}.{version.micro}")
    else:
        print(f"âŒ Python {version.major}.{version.minor}.{version.micro} (requerido: 3.10+)")
        return False
    
    # Verificar dependencias crÃ­ticas
    critical_deps = ['PySide6', 'yaml', 'psutil', 'requests']
    failed_deps = []
    
    for dep in critical_deps:
        try:
            __import__(dep)
            print(f"âœ… {dep}")
        except ImportError:
            print(f"âŒ {dep}")
            failed_deps.append(dep)
    
    # Verificar archivos principales
    critical_files = [
        'main.py', 'test_suite.py', 'requirements.txt',
        'config/config.yaml', 'core/app_core.py'
    ]
    
    missing_files = []
    for file in critical_files:
        if Path(file).exists():
            print(f"âœ… {file}")
        else:
            print(f"âŒ {file}")
            missing_files.append(file)
    
    # Resultado
    if not failed_deps and not missing_files:
        print("\nğŸ‰ Â¡Diagnosis exitosa! Sistema listo para usar.")
        print("ğŸ’¡ Puedes ejecutar: python test_suite.py")
        return True
    else:
        print(f"\nâš ï¸ Problemas encontrados:")
        if failed_deps:
            print(f"  ğŸ“¦ Dependencias faltantes: {', '.join(failed_deps)}")
            print(f"  ğŸ’¡ SoluciÃ³n: pip install -r requirements.txt")
        if missing_files:
            print(f"  ğŸ“ Archivos faltantes: {', '.join(missing_files)}")
            print(f"  ğŸ’¡ SoluciÃ³n: Verificar instalaciÃ³n del proyecto")
        return False

def run_test_suite(test_type='all', verbose=False, buffer=False):
    """Ejecutar tests especÃ­ficos"""
    
    # Mapeo de tipos de test a clases
    test_mapping = {
        'environment': 'TestEnvironment',
        'dependencies': 'TestDependencies',
        'core': 'TestCoreModules',
        'config': 'TestConfiguration',
        'plugins': 'TestPluginSystem',
        'app': 'TestApplication',
        'ui': 'TestUIComponents',
        'threads': 'TestThreadManager',
        'tools': 'TestToolManager',
        'specific': 'TestSpecificPlugins',
        'assets': 'TestAssetManager',
        'files': 'TestFileStructure',
        'integration': 'TestIntegration',
        'performance': 'TestPerformance'
    }
    
    # Construir comando
    if test_type == 'all':
        cmd = ['python', 'test_suite.py']
    elif test_type == 'critical':
        # Tests crÃ­ticos: environment, dependencies, core
        cmd = ['python', '-m', 'unittest', 
               'test_suite.TestEnvironment',
               'test_suite.TestDependencies', 
               'test_suite.TestCoreModules']
        if verbose:
            cmd.append('-v')
        if buffer:
            cmd.append('-b')
    elif test_type in test_mapping:
        cmd = ['python', '-m', 'unittest', f'test_suite.{test_mapping[test_type]}']
        if verbose:
            cmd.append('-v')
        if buffer:
            cmd.append('-b')
    else:
        print(f"âŒ Tipo de test desconocido: {test_type}")
        return False
    
    # Ejecutar comando
    print(f"\nğŸš€ Ejecutando tests: {test_type}")
    print(f"ğŸ’» Comando: {' '.join(cmd)}")
    print("-" * 50)
    
    try:
        result = subprocess.run(cmd, cwd=Path.cwd())
        return result.returncode == 0
    except Exception as e:
        print(f"âŒ Error ejecutando tests: {e}")
        return False

def main():
    """FunciÃ³n principal"""
    parser = argparse.ArgumentParser(
        description='ğŸ§ª Gaming Helper Overlay Test Runner',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:
  python run_tests.py                    # Ejecutar todos los tests
  python run_tests.py environment        # Solo tests de entorno
  python run_tests.py --list             # Listar tests disponibles
  python run_tests.py quick              # Diagnosis rÃ¡pida
  python run_tests.py critical -v        # Tests crÃ­ticos con verbosidad
  python run_tests.py plugins --buffer   # Tests de plugins con buffer
        """
    )
    
    parser.add_argument('test_type', nargs='?', default='all',
                       help='Tipo de test a ejecutar (default: all)')
    parser.add_argument('-v', '--verbose', action='store_true',
                       help='Salida verbose para unittest')
    parser.add_argument('-b', '--buffer', action='store_true',
                       help='Buffer output durante ejecuciÃ³n')
    parser.add_argument('-l', '--list', action='store_true',
                       help='Listar tests disponibles')
    parser.add_argument('-q', '--quick', action='store_true',
                       help='Solo diagnosis rÃ¡pida')
    
    args = parser.parse_args()
    
    print_header()
    
    # Mostrar tests disponibles
    if args.list:
        print_available_tests()
        return
    
    # Diagnosis rÃ¡pida
    if args.quick or args.test_type == 'quick':
        success = run_quick_diagnosis()
        sys.exit(0 if success else 1)
    
    # Verificar que el archivo test_suite.py existe
    if not Path('test_suite.py').exists():
        print("âŒ Error: test_suite.py no encontrado")
        print("ğŸ’¡ AsegÃºrate de estar en el directorio del proyecto")
        sys.exit(1)
    
    # Ejecutar tests
    success = run_test_suite(args.test_type, args.verbose, args.buffer)
    
    if success:
        print(f"\nğŸ‰ Tests completados exitosamente!")
    else:
        print(f"\nâŒ Algunos tests fallaron. Revisa la salida arriba.")
        print(f"ğŸ’¡ Para diagnosis: python run_tests.py quick")
        print(f"ğŸ’¡ Para tests crÃ­ticos: python run_tests.py critical -v")
    
    sys.exit(0 if success else 1)

if __name__ == '__main__':
    main()
